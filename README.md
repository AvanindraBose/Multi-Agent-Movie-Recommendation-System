# ðŸŽ¬ Persona-Driven Cine-Agent

*A Multi-Agent Movie Recommendation System using LLMs, SQL Reasoning & Semantic Retrieval*

---

## ðŸ§  Overview

**Persona-Driven Cine-Agent** is an intelligent multi-agent recommendation system that behaves like a personal movie concierge.

Instead of giving generic recommendations, the system:

* Learns **how a user thinks**
* Understands **what they emotionally mean**
* Uses both **behavioral data** and **story similarity**
* Produces **personalized explanations**

This is not a simple recommender â€” it is a **reasoning system**.

---

## ðŸš€ Key Idea

Traditional recommenders answer:

> *â€œUsers like you watched this.â€*

Cine-Agent answers:

> *â€œBased on your past taste in melancholic psychological dramas and your current request for something emotionally dark, hereâ€™s a curated recommendation and why.â€*

---

## ðŸ— Architecture

The system uses a **4-agent cognitive architecture**.

```
User Query
   â†“
Agent 1 â€” Persona Compiler
   â†“
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚               â”‚               â”‚
SQL Agent     RAG Agent      User Profile
(popularity)  (semantic)     (history)
 â”‚               â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â–º Decision Agent â—„â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
        Final Personalized Recommendation
```

---

## ðŸ§© Agents Explained

### 1ï¸âƒ£ Persona & Query Refiner

**Role:** Understand what the user *actually means*

Input:

```
"I want something visually stunning and philosophical"
```

Output (structured plan):

```json
{
  "intent": "philosophical emotional film",
  "target_tags": ["thought-provoking","existential","atmospheric"],
  "target_genres": ["drama","sci-fi"]
}
```

It uses:

* Userâ€™s top rated movies
* Userâ€™s personal tags
* Global tag vocabulary
* Fuzzy matching

---

### 2ï¸âƒ£ SQL ReAct Agent â€” Structured Intelligence

**Role:** Find socially strong candidates

Uses:

* Ratings
* Tags
* Average rating computation

Example reasoning:

```
Thought: find psychological movies
Action: SQL query
Observation: candidate movies
Thought: rank by average rating
```

This agent performs **dynamic SQL reasoning**, not static queries.

---

### 3ï¸âƒ£ Semantic RAG Agent â€” Narrative Intelligence

**Role:** Find movies with similar *story feeling*

Uses:

* Plot overview embeddings
* Vector similarity search

Understands:

> tone, atmosphere, emotion, narrative theme

Not popularity.

---

### 4ï¸âƒ£ Profile-Aware Summarizer â€” Decision Maker

**Role:** Final human-like explanation

It merges:

| Source  | What it means       |
| ------- | ------------------- |
| SQL     | socially good       |
| RAG     | emotionally similar |
| Persona | personally relevant |

Then explains:

> why *you* will like it

---

## ðŸ“Š Data Sources

### MovieLens Dataset

Used for:

* Ratings
* User tags
* Collaborative filtering

### TMDB Dataset

Used for:

* Plot overview
* Semantic similarity
* Story understanding

---

## ðŸ—„ Database Design

Tables:

```
movies(movieId, title, genres)
ratings(userId, movieId, rating, timestamp)
tags(userId, movieId, tag, timestamp)
tmdb_info(tmdbId, title, overview, release_date, genres)
```

No aggregation stored â€” agents compute dynamically.

---

## ðŸ” Retrieval Strategy

| Method     | Purpose                  | Intelligence Type      |
| ---------- | ------------------------ | ---------------------- |
| SQL Agent  | best rated tagged movies | Social intelligence    |
| Vector RAG | story similarity         | Emotional intelligence |
| Summarizer | ranking & explanation    | Cognitive reasoning    |

---

## ðŸ§  Why Multi-Agent?

Single LLM systems hallucinate because they try to:

* Understand
* Retrieve
* Rank
* Explain

All at once.

We separate thinking into roles:

| Agent      | Thinking Type          |
| ---------- | ---------------------- |
| Persona    | interpretive reasoning |
| SQL        | symbolic reasoning     |
| RAG        | semantic reasoning     |
| Summarizer | narrative reasoning    |

This dramatically increases reliability.

---

## ðŸ›  Tech Stack

| Component  | Technology                    |
| ---------- | ----------------------------- |
| LLM        | Ollama (Llama 3.1)            |
| Embeddings | nomic-embed-text              |
| Vector DB  | ChromaDB                      |
| Database   | SQLite                        |
| Framework  | LangChain Classic + LangGraph |
| Similarity | RapidFuzz                     |

---

## ðŸ“¦ How It Works End-to-End

1. User asks:

```
Find a dark emotional psychological movie
```

2. Persona Agent:
   â†’ interprets meaning

3. SQL Agent:
   â†’ finds highly rated psychological movies

4. RAG Agent:
   â†’ finds narratively similar stories

5. Decision Agent:
   â†’ merges and explains

6. Final Output:

```
Based on your past preference for character-driven dramas and
your request for a dark emotional film, I recommend...
```

---

## ðŸ§ª Example Output

> **Recommendation: Memento (2000)**
> Because you tend to rate introspective psychological narratives highly and requested a dark emotional experience, this film aligns with both your historical taste and current mood.

---

## ðŸŽ¯ What Makes This Special

This project demonstrates:

* LLM reasoning orchestration
* Structured + semantic retrieval fusion
* Tool-using agents
* Deterministic AI behavior
* Explainable recommendations

Not just AI output â€” **AI decision making**.

---

## ðŸ§­ Future Extensions

* Streaming watch history adaptation
* Reinforcement feedback learning
* Memory across sessions (LangGraph state)
* Conversational follow-up recommendations
* Hybrid ranking scoring

---
